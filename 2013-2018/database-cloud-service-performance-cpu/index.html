<html><head>
<link rel=canonical href=https://blog.dbi-services.com/database-cloud-service-performance-cpu />
<meta name=description content='A blog post from 2015 about DataBase Cloud Service performance – CPU'>
<title>DataBase Cloud Service performance – CPU</title>
<link rel=stylesheet href=../../style.css media=all>   

</head><body>


<p class=aboutme>
<br/>
<table width=100%>
<tr>
<td>
<div class=message>Follow:
<a href=https://linkedin.com/in/franckpachot>Linkedin</a>, <a href=https://twitter.com/franckpachot>Twitter</a>, <a href=https://www.youtube.com/@franckpachot/community>Youtube</a>, <a href=https://mastodon.social/@FranckPachot>Mastodon</a>, <a href=https://dev.to/franckpachot>dev.to</a>
 </div>
</td><td>
<img src=https://pbs.twimg.com/profile_images/1487359683119788033/4ejaJ4S5_400x400.jpg height=100 width=100/>
</td>
</tr>
</table>
<br/>
</p>


<p class=firstpub>This was first published on <a href=https://blog.dbi-services.com/database-cloud-service-performance-cpu>https://blog.dbi-services.com/database-cloud-service-performance-cpu</a> (2015-08-30)<br>Republishing here for new followers. The content is related to the the versions available at the publication date</p>
								<h1 class="entry-title">DataBase Cloud Service performance – CPU</h1>
		<div class="content-inner">
			
						
						
		   
			<p><img style="float:right" src="../wp-insides/uploads/sites/2/2015/08/cloud-300x300.png" alt="cloud" width="50" height="50"> In the previous <a href="http://blog.dbi-services.com/database-cloud-service-performance-iops/" title="DataBase Cloud Service performance – IOPS">blog post</a> I&#8217;ve measured the physical i/o performance, with SLOB.</p>
<p>We can run the same with a small size of data and a large buffer cache in order to measure logical reads (LIOs) and CPU performance.
<span id="more-3437"></span></p>
<h1>What is an OCPU?</h1>
<p>Except if you are licenced in NUP, you are already used to pay the Oracle database usage per CPU. The processor metric is socket for Standard Edition, or cores (with a core factor) for Enterprise Edition. And you pay for the processors you have physically, except for the hypervisors where Oracle accepts to count the vCPUs.</p>
<p>In the Cloud, you&#8217;re on Oracle VM where hard partitioning is accepted. Pricing is done on virtual CPU &#8211; called &#8216;OCPU&#8217;.</p>
<p>When you create a new service in the Database Cloud Services, you choose the &#8216;compute shape&#8217; you want:
<a href="http://blog.dbi-services.com/wp-insides/uploads/sites/2/2015/08/OC4.png" rel="lightbox[3437]"><img src="../wp-insides/uploads/sites/2/2015/08/OC4.png" alt="OC4" width="895" height="300" class="alignnone size-full wp-image-3441"></a></p>
<p>The definition of OCU is: OCPU is defined as the CPU capacity equivalent of one physical core of an Intel Xeon processor with
hyper threading enabled. And you pay the Database Cloud Services per OCP (see <a href="https://cloud.oracle.com/database?tabID=1406491812773" target="_blank">pricing list</a>). Here I&#8217;ve chosen 2 OCPU which means that I have 4 threads.</p>
<p>I&#8217;ve already posted the details of lscpu and /proc/cpuinfo in a <a href="http://blog.dbi-services.com/oracle-database-cloud-service-dbaas/" title="Oracle Database Cloud Service – DBaaS" target="_blank">previous post</a>.</p>
<p>Basically we have 4 threads from Intel Xeon E5-2690 v2 (3GHz) cores. So it looks like we have Sun Server X4-2 behind.
It&#8217;s virtualized with Xen, So probably OVM (Twitter discussion about it: <a href="https://twitter.com/OracleSK/status/636544116483072000" target="_blank">https://twitter.com/OracleSK/status/636544116483072000</a>)</p>
<h1>Run LIOs test</h1>
<p>Let&#8217;s run the cached SLOB at it and compare it with a physical machine with same E5-2690 v2.
I&#8217;ve set a large buffer cache, and small SLOB scale (but large enough because I don&#8217;t want to be in cpu cache).</p>
<p><pre>
[oracle@test-perf SLOB]$ sh runit.sh 1
NOTIFY : 2015.08.30-11:38:48 :
NOTIFY : 2015.08.30-11:38:48 : Conducting SLOB pre-test checks.

UPDATE_PCT: 0
RUN_TIME: 600
WORK_LOOP: 0
SCALE: 500M (64000 blocks)
WORK_UNIT: 64
REDO_STRESS: LITE
HOT_SCHEMA_FREQUENCY: 0
DO_HOTSPOT: FALSE
HOTSPOT_MB: 8
HOTSPOT_OFFSET_MB: 16
HOTSPOT_FREQUENCY: 3
THINK_TM_FREQUENCY: 0
THINK_TM_MIN: .1
THINK_TM_MAX: .5
...
NOTIFY : 2015.08.30-11:49:07 : SLOB test is complete.
</pre></p>
<p>In the AWR report I check that I&#8217;m doing only logical reads:
<pre>
Instance Efficiency Percentages (Target 100%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            Buffer Nowait %:  100.00       Redo NoWait %:  100.00
            Buffer  Hit   %:  100.00    In-memory Sort %:  100.00
            Library Hit   %:  100.00        Soft Parse %:   99.66
         Execute to Parse %:   99.98         Latch Hit %:  100.00
Parse CPU to Parse Elapsd %:  100.00     % Non-Parse CPU:   99.99
          Flash Cache Hit %:    0.00
</pre></p>
<p>Well, this it is probably the only case where I check the &#8216;buffer cache hit ratio&#8217; in an AWR report&#8230;</p>
<p>Then here are the LIOPS &#8211; logical reads per second:</p>
<p><pre>
Load Profile                    Per Second   Per Transaction  Per Exec  Per Call
~~~~~~~~~~~~~~~            ---------------   --------------- --------- ---------
             DB Time(s):               1.0              17.7      0.00      5.78
              DB CPU(s):               1.0              17.6      0.00      5.74
      Background CPU(s):               0.0               0.1      0.00      0.00
      Redo size (bytes):           4,274.4          75,644.6
  Logical read (blocks):         595,168.5      10,532,749.6
          Block changes:              16.5             292.8
 Physical read (blocks):               0.1               2.1
Physical write (blocks):               1.0              18.3
       Read IO requests:               0.1               2.1
      Write IO requests:               0.5               9.1
           Read IO (MB):               0.0               0.0
          Write IO (MB):               0.0               0.1
           IM scan rows:               0.0               0.0
Session Logical Read IM:
             User calls:               0.2               3.1
           Parses (SQL):               2.0              34.4
      Hard parses (SQL):               0.0               0.1
     SQL Work Area (MB):               0.1               0.8
                 Logons:               0.1               1.2
         Executes (SQL):           9,002.4         159,315.5
              Rollbacks:               0.0               0.0
           Transactions:               0.1
</pre></p>
<p>DB CPU usage is 1 second per second, which is what I want: I&#8217;ve run SLOB on one thread only, and all in CPU.</p>
<p>So I can do 595168 LIOPS with one thread on that platform.</p>
<p>Let&#8217;s compare with a physical server with same E5-2690 v2 (<a href="https://twitter.com/kevinclosson/status/636905086338342913">https://twitter.com/kevinclosson/status/636905086338342913</a>)</p>
<p><a href="http://blog.dbi-services.com/wp-insides/uploads/sites/2/2015/08/SLOB-physical.png" rel="lightbox[3437]"><img src="../wp-insides/uploads/sites/2/2015/08/SLOB-physical.png" alt="SLOB-physical" width="746" height="429" class="alignnone size-full wp-image-3444"></a></p>
<p>This is good. I&#8217;ve no overhead (less than 0.5%) from being virtualized, and in the cloud, here.</p>
<h1>%steal</h1>
<p>Since Linux 2.6.11 (and we are here in OEL 6.4 &#8211; Linux 2.6.39), virtual CPU time accounting counts the time where process is on vCPU but waiting for physical CPU to be scheduled by the hypervisor. It&#8217;s an idle time displayed &#8216;steal&#8217; time:</p>
<p><pre>
11:00:01 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle
11:10:01 AM     all      0.74      0.00      0.35      0.10      0.04     98.77
11:20:01 AM     all      0.21      0.00      0.33      0.08      0.03     99.35
11:30:01 AM     all      1.24      0.00      0.49      0.12      0.04     98.12
11:40:01 AM     all     13.17      0.00      1.66      0.13      0.02     85.01
11:50:01 AM     all     20.72      0.00      2.36      0.09      0.01     76.82
12:00:01 PM     all      0.20      0.00      0.32      0.09      0.04     99.34
</pre></p>
<p>Note that %iowait + %steal + %idle are all idle time. They detail on why it is idle (uninterruptible system call, wait for physical CPU, voluntary idle)</p>
<p>The Oracle Cloud Services are probably not very busy yet, but even in the future, I don&#8217;t expect to see that %steal increasing because we pay for the allocated OCPU.</p>
<h1>Threads</h1>
<p>On a physical server, if I&#8217;ve 2 hyper-threaded cores, I expect to be able to run 2 processes with this LIO rate. Each process running on one core. If I run 4 processes, then the LIO rate will not double because hyperthreading don&#8217;t double the power of one core. It depends on the workload (time spend by one thread accessing RAM can be used by the other thread to process cpu).</p>
<p>From above, the LIO rate of one thread in my 2 OCPU VM was 595,168 LIO/s</p>
<p><pre>
Load Profile                    Per Second   Per Transaction  Per Exec  Per Call
~~~~~~~~~~~~~~~            ---------------   --------------- --------- ---------
            DB Time(s):               1.0              17.7      0.00      5.78
             DB CPU(s):               1.0              17.6      0.00      5.74
 Logical read (blocks):         595,168.5      10,532,749.6
</pre></p>
<p>Here is the result if I run two threads:</p>
<p><pre>
Load Profile                    Per Second   Per Transaction  Per Exec  Per Call
~~~~~~~~~~~~~~~            ---------------   --------------- --------- ---------
            DB Time(s):               2.0              34.3      0.00      9.03
             DB CPU(s):               2.0              34.3      0.00      9.03
 Logical read (blocks):       1,197,483.8      20,590,801.7
</pre></p>
<p>Here I have two threads running (DB CPU per second = 2) and LIOPS is 1,197,483.8 , which is exactly two times the 595,168.5 from one thread.</p>
<p>Good. My 2 OCPU are equivalent to two cores.</p>
<p>Let&#8217;s try 3 threads:</p>
<p><pre>
Load Profile                    Per Second   Per Transaction  Per Exec  Per Call
~~~~~~~~~~~~~~~            ---------------   --------------- --------- ---------
            DB Time(s):               3.0              50.9      0.00     14.38
             DB CPU(s):               3.0              50.9      0.00     14.38
 Logical read (blocks):       1,616,011.6      27,785,749.9
</pre></p>
<p>Here, the factor from one thread is 1,616,011.6/595,168.5=2.7 which is good again. The additional thread had to share the core with another one.</p>
<p>And now all my 4 threads:</p>
<p><pre>
Load Profile                    Per Second   Per Transaction  Per Exec  Per Call
~~~~~~~~~~~~~~~            ---------------   --------------- --------- ---------
            DB Time(s):               4.0              68.6      0.00     17.03
             DB CPU(s):               3.9              67.5      0.00     16.76
 Logical read (blocks):       2,110,565.1      36,241,718.6
</pre></p>
<p>The DB CPU per second is not exactly 4.0 because I&#8217;ve other activity on the server so my 4 threads cannot use the 4 cpu.</p>
<p>The factor from one thread 2,110,565.1/595,168.5=3.5 show that we had an additional 0.7 with a second thread that shares a core.</p>
<p>Note that this &#8216;0.7&#8217; factor is not a general number. It&#8217;s here with that SLOB configuration. Don&#8217;t expect the same from hyper-threading for any application. Even with SLOB a different WORK_UNIT parameter will have different hyper-threading benefit.</p>
<h3>Update one week later</h3>
<p>Here is an update after one week.
I&#8217;ve run the test with 1 to 8 threads scheduled every 15 minutes during one week on European cloud. Here is the averages over a week:
<pre>
DB Time(s)  DB CPU(s)      LIOPS  FACTOR
         1        1.0    580 461     1.0
         2        2.0  1 110 536     1.9
         3        3.0  1 615 678     2.8
         4        4.0  2 117 588     3.7
         5        4.0  2 085 537     3.6
         6        4.0  2 069 127     3.6
         7        4.0  2 047 572     3.5
         8        4.0  1 962 077     3.4
</pre>
We can see that raising the number of threads raises the logical reads rate until we reach the 4 cpu. Then, DB Time is increasing (including wait in runqueue) and LIOPS decrease a bit because of that context switch overhead. Another remark is that we can&#8217;t say that the the first two threads always go to 2 cores. The factor being less than 2 for two threads, we can guess that sometimes they are hyperthreaded in the same core.</p>
<h1>So what?</h1>
<p>The numbers show that we have exactly what we have paid for: 2 OCP that are equivalent to 2 cores with 2-way hyper-threading. Of course, it&#8217;s good news. Now I have a good benchmark to check if this remains true when the Oracle Cloud Services will be more busy. I&#8217;ll keep an eye on the %steal that must remain near 0%</p>
<table class="rw-rating-table rw-ltr rw-left rw-no-labels"><tr><td><nobr>&nbsp;</nobr></td><td><div class="rw-left"><div class="rw-ui-container rw-class-blog-post rw-urid-34380" data-img="http://blog.dbi-services.com/wp-insides/uploads/sites/2/2015/08/cloud-300x300.png"></div></div></td></tr></table>							
		</div><!--/content-inner-->
<div class="comment-wrap ">


			<!-- If comments are open, but there are no comments. -->

	 

								<div id="respond" class="comment-respond">

<p class=aboutme>
<br/>
<table width=100%>
<tr>
<td>
<div class=message>Follow:
<a href=https://linkedin.com/in/franckpachot>Linkedin</a>, <a href=https://twitter.com/franckpachot>Twitter</a>, <a href=https://www.youtube.com/@franckpachot/community>Youtube</a>, <a href=https://mastodon.social/@FranckPachot>Mastodon</a>, <a href=https://dev.to/franckpachot>dev.to</a>
 </div>
</td><td>
<img src=https://pbs.twimg.com/profile_images/1487359683119788033/4ejaJ4S5_400x400.jpg height=100 width=100/>
</td>
</tr>
</table>
<br/>
</p>


</body></html>
